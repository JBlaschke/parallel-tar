- name: Package archive
  shell: bash
  env:
    TARGET: ${{ matrix.target }}
    TAG: ${{ github.ref_name }}
    ARCHIVE_EXT: ${{ matrix.archive_ext }}
    # Optional override: comma/space separated binary names, e.g. "parallel-tar parallel-idx view-idx"
    BIN_NAMES: ${{ vars.BIN_NAMES }}
  run: |
    set -euo pipefail

    python - <<'PY'
    import json, os, pathlib, shutil, subprocess, tarfile, zipfile, re

    target = os.environ["TARGET"]
    tag = os.environ["TAG"]
    archive_ext = os.environ["ARCHIVE_EXT"]
    bin_names_override = (os.environ.get("BIN_NAMES") or "").strip()

    meta = json.loads(subprocess.check_output(["cargo", "metadata", "--no-deps", "--format-version", "1"]))

    # Figure out which package to package:
    # - Prefer the package whose manifest_path is ./Cargo.toml
    # - Otherwise use the first workspace default member
    root_manifest = pathlib.Path("Cargo.toml").resolve()
    root_pkg = next(
        (p for p in meta["packages"] if pathlib.Path(p["manifest_path"]).resolve() == root_manifest),
        None
    )
    if root_pkg is None:
        default_members = meta.get("workspace_default_members") or meta.get("workspace_members")
        root_id = default_members[0]
        root_pkg = next(p for p in meta["packages"] if p["id"] == root_id)

    # Determine all bin targets
    bin_targets = [t for t in root_pkg.get("targets", []) if "bin" in t.get("kind", [])]
    detected_bins = [t["name"] for t in bin_targets]

    if bin_names_override:
        # Split by commas or whitespace
        bin_names = [x for x in re.split(r"[,\s]+", bin_names_override) if x]
    else:
        # Default: package ALL detected bins
        bin_names = detected_bins or [root_pkg["name"]]

    exe = ".exe" if target.endswith("windows-msvc") else ""

    # Name archive by package name (not by one of the binaries)
    pkg_name = root_pkg["name"]
    out_name = f"{pkg_name}-{tag}-{target}"

    dist = pathlib.Path("dist") / out_name
    if dist.exists():
        shutil.rmtree(dist)
    dist.mkdir(parents=True)

    # Copy binaries
    missing = []
    for name in bin_names:
        built = pathlib.Path("target") / target / "release" / f"{name}{exe}"
        if not built.exists():
            missing.append(str(built))
            continue
        shutil.copy2(built, dist / f"{name}{exe}")

    if missing:
        raise SystemExit(
            "Some expected binaries were not found after build:\n"
            + "\n".join(f"  - {m}" for m in missing)
            + "\n\nDetected bin targets from cargo metadata:\n"
            + "\n".join(f"  - {b}" for b in detected_bins)
            + "\n\nTip: Ensure `cargo build ... --bins` ran and the target matches."
        )

    # Copy common docs if present
    for fn in ("README.md", "README.txt", "LICENSE", "LICENSE.md", "COPYING"):
        p = pathlib.Path(fn)
        if p.exists():
            shutil.copy2(p, dist / p.name)

    # Create archive
    archive = pathlib.Path(f"{out_name}.{archive_ext}")
    if archive_ext == "zip":
        with zipfile.ZipFile(archive, "w", compression=zipfile.ZIP_DEFLATED) as z:
            for file in dist.rglob("*"):
                if file.is_file():
                    z.write(file, arcname=f"{out_name}/{file.relative_to(dist).as_posix()}")
    elif archive_ext == "tar.gz":
        with tarfile.open(archive, "w:gz") as t:
            t.add(dist, arcname=out_name)
    else:
        raise SystemExit(f"Unsupported archive_ext={archive_ext}")

    print(f"Packaged bins: {', '.join(bin_names)}")
    print(f"Created {archive}")
    PY

